# Backend Service for AI Mock Interview

## 1. Project Overview

This project is a mock interview platform that helps candidates prepare for real job interviews through an AI-powered interviewer.

A candidate logs in, uploads their resume, and specifies the company & role they are preparing for.

The system parses the resume, stores embeddings in a vector database, and retrieves contextually relevant questions.

The AI interviewer (powered by Cerebras Llama 3.3) conducts the interview in real-time over LiveKit, with Cartesia STT/TTS enabling natural speech-to-speech interaction.

The interview adapts dynamically:

Starts with resume-based questions

Moves to role/company-specific technical or behavioral questions

Adds DSA or system design questions depending on the role context

After the interview, the candidate receives automated feedback generated by the AI, covering their strengths, weaknesses, and improvement areas.

This repository contains the backend for **[AI Mock Interview]**, built with **FastAPI**.  
It handles core functionalities like user authentication, interview management, feedback collection, and centralized configuration.  

It also integrates AI services, live communication, and object storage for resumes.

---

## 2. Architecture
The backend follows a **domain-driven architecture (DDD)**, with self-contained domains:

### **Domains**
1. **Auth** – User registration, login, roles, and JWT-based authentication.
2. **Interview** – Creation, scheduling, and retrieval of interviews.
3. **Feedback** – Collecting and managing feedback from interviewers or candidates.
4. **Config** – Centralized configurations

### **External Integrations**
- **Cerebras & LLaMA 3.3** – For AI-based tasks like question generation or scoring.
- **Cartesia** – Speech-to-text and speech analysis services.
- **LiveKit** – Real-time video/audio communication for interviews.
- **PostgreSQL + pgvector** – Database with vector search for AI embeddings.
- **AWS Object Storage (S3)** – Resume file storage.

---

## 3. Project Structure

```
backend/
│
├── auth/
│ ├── models.py
│ ├── schemas.py
│ ├── services.py
│ ├── routes.py
│ └── init.py
│
├── interview/
│ ├── models.py
│ ├── schemas.py
│ ├── services.py
│ ├── routes.py
│ └── init.py
│
├── feedback/
│ ├── models.py
│ ├── schemas.py
│ ├── services.py
│ ├── routes.py
│ └── init.py
│
├── config/
│ ├── database.py
│ ├── object_storage.py
│ ├── settings.py
│ └── init.py
│
├── main.py
├── requirements.txt
├── alembic/
├── tests/
├── Dockerfile
└── .github/workflows/ci-cd.yml
```

---

## 4. Tech Stack
- **Backend Framework:** FastAPI
- **Language:** Python 3.10+
- **Database:** PostgreSQL + pgvector
- **Object Storage:** AWS S3
- **Authentication:** JWT tokens
- **Real-time Communication:** LiveKit
- **AI Services:** Cerebras, LLaMA 3.3
- **Speech Processing:** Cartesia
- **Containerization:** Docker
- **Deployment:** AWS
- **CI/CD:** GitHub Actions

---

## 5. Key Features

- Hybrid Interview Flow (STT → Batch LLM → Streaming TTS)

    - Candidate speaks naturally.

    - Pause detection triggers AI response.

    - AI replies in streaming voice for a realistic, fluid conversation.

- Resume-Aware Questioning

    - Candidate uploads a resume.

    - Resume parsed, embedded, and stored in pgvector.

    - AI interviewer asks contextual questions about past experience & projects.

- Company & Role-Specific Questioning

    - Web-scraped / pre-curated Q&A pairs stored in vector DB.

    - Relevant interview questions retrieved dynamically based on chosen role/company.

- Adaptive Question Flow

    - Interview adapts in real-time.

    - Starts with resume-based intro → transitions to role-specific technical/behavioral → adds DSA/system design as needed.

- Structured Feedback Generation

    - AI provides post-interview feedback on clarity, depth, technical correctness, and communication.

    - Stored in Postgres for candidate review.

- Monolithic Backend (MVP Ready)

    - All services (Auth, Resume, Interview, Feedback) run inside one FastAPI app.

    - Easier to iterate, debug, and deploy.

- Vector Database Integration (pgvector + Postgres)

    - Used for resume embeddings, question bank, and ideal answer comparisons.

    - Enables semantic search and contextual question generation.